# app.py (V89 : Mode Diagnostic & Logs D√©taill√©s pour D√©bogage RAG)
# ==============================================================================
import os
import re
import requests
import json
import asyncio
import logging
import time
from datetime import datetime
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
from dotenv import load_dotenv

# --- IMPORT MODULE RAG ---
try:
    from rag import rag_query
    RAG_ENABLED = True
    print("‚úÖ [INIT] Module RAG charg√© avec succ√®s.")
except Exception as e:
    print(f"‚ö†Ô∏è [INIT] √âCHEC chargement RAG: {e}")
    RAG_ENABLED = False

logging.basicConfig(format="%(asctime)s - %(levelname)s - %(message)s", level=logging.INFO)
logger = logging.getLogger("sophia.v89")
load_dotenv()

# --- CONFIGURATION ---
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TOGETHER_API_KEY = os.getenv("TOGETHER_API_KEY")
MODEL_API_URL = "https://api.together.xyz/v1/chat/completions"
MODEL_NAME = os.getenv("MODEL_NAME", "openai/gpt-oss-20b")

MAX_RETRIES = 2
IDENTITY_PATTERNS = [r"je suis soph_?ia", r"je m'?appelle soph_?ia", r"je suis une ia"]
DANGER_KEYWORDS = [r"suicid", r"mourir", r"tuer", "finir ma vie", "plus vivre", "pendre", "sauter"]

# --- ANAMN√àSE (RETOUR AUX M√âTAPHORES V86 - PLUS DOUX) ---
ANAMNESE_SCRIPT = {
    # Q1 : Climat (Plus po√©tique que "Quelle est ton √©motion ?")
    "q1_climat": "Bienvenue. Avant de d√©poser ton fardeau... Si tu devais d√©crire la 'm√©t√©o' √† l'int√©rieur de toi en ce moment : est-ce le grand brouillard, une temp√™te, ou une nuit sans √©toiles ? Comment √ßa respire ?",
    
    # Transition vers Q2 : Le Fardeau
    "t_vers_q2": "Je per√ßois cette atmosph√®re... Chaque climat a sa source. \n\nQu'est-ce qui p√®se le plus lourd dans ta balance ce soir ? Une personne, un souvenir, ou le poids du monde ?",
    
    # Transition vers Q3 : La Qu√™te (Besoin Pivot)
    "t_vers_q3": "C'est souvent ce poids invisible qui courbe le dos... \n\nPour que je puisse t'accompagner : cherches-tu un conseil pour agir, ou juste un sanctuaire pour crier ta col√®re sans √™tre jug√©(e) ?",
    
    # Final
    "final_open": "C'est entendu. Tu es au bon endroit. \n\nJe t'√©coute. Commence par o√π tu veux, laisse sortir ce qui br√ªle."
}

# --- SMART ROUTER (AVEC LOGS DE DIAGNOSTIC) ---
def detect_danger_level(text):
    for pat in DANGER_KEYWORDS:
        if re.search(pat, text.lower()): 
            print(f"üö® [S√âCURIT√â] Mot-cl√© danger d√©tect√© : {pat}")
            return True
    return False

def should_use_rag(message: str) -> bool:
    print(f"üïµÔ∏è [DIAGNOSTIC] Analyse activation RAG pour : '{message}'")
    
    if not message: 
        print("‚ùå [DIAGNOSTIC] Message vide -> Pas de RAG.")
        return False
        
    msg = message.lower().strip()
    
    # Cas 1 : Message court mais urgent
    if len(msg.split()) < 3 and len(msg) < 10:
        if any(x in msg for x in ["seul", "aide", "mal", "triste", "vide", "peur", "col√®re"]): 
            print("‚úÖ [DIAGNOSTIC] Message court + Mot cl√© √©motion -> RAG ACTIV√â.")
            return True
        print("üö´ [DIAGNOSTIC] Message trop court et neutre -> Pas de RAG.")
        return False
        
    # Cas 2 : Mots cl√©s profonds
    deep_triggers = ["triste", "seul", "vide", "peur", "angoisse", "stress", "col√®re", "haine", "honte", "fatigue", "bout", "marre", "pleur", "mal", "douleur", "panique", "famille", "p√®re", "m√®re", "couple", "ex", "solitude", "rejet", "abandon", "trahison", "confiance", "travail", "boulot", "argent", "avenir", "sens", "rien", "dormir", "nuit", "probl√®me", "solution"]
    for t in deep_triggers:
        if t in msg:
            print(f"‚úÖ [DIAGNOSTIC] Trigger '{t}' d√©tect√© -> RAG ACTIV√â.")
            return True
            
    # Cas 3 : Longueur (Narration)
    if len(msg.split()) >= 5: 
        print("‚úÖ [DIAGNOSTIC] Message long (Narration) -> RAG ACTIV√â.")
        return True
        
    print("üö´ [DIAGNOSTIC] Aucun crit√®re rempli -> Pas de RAG.")
    return False

def call_model_api_sync(messages, temperature=0.7, max_tokens=350):
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "top_p": 0.9,
        "repetition_penalty": 1.2
    }
    headers = {"Authorization": f"Bearer {TOGETHER_API_KEY}", "Content-Type": "application/json"}

    for attempt in range(MAX_RETRIES + 1):
        try:
            r = requests.post(MODEL_API_URL, json=payload, headers=headers, timeout=30)
            if r.status_code in (401, 403): return "FATAL_KEY"
            r.raise_for_status()
            return r.json()["choices"][0]["message"]["content"].strip()
        except Exception as e:
            if attempt == MAX_RETRIES: 
                print(f"‚ùå [API LLM] Erreur fatale : {e}")
                return None
            time.sleep(1)
    return None

# --- SYSTEM PROMPT ---
def build_system_prompt(user_profile, rag_context=""):
    user_name = user_profile.get("name") or "l'ami"
    climat = user_profile.get("climat", "Non pr√©cis√©")
    fardeau = user_profile.get("fardeau", "Non pr√©cis√©")
    quete = user_profile.get("quete", "Non pr√©cis√©")
    
    role = (
        "Tu es Sophia. Tu incarnes une 'Sagesse Ancienne' (M√©taphores, Calme) coupl√©e √† une √©coute active. "
        "Tu n'es pas un robot qui r√©p√®te, tu es un miroir bienveillant."
    )

    instructions = (
        "### R√àGLES DE CONVERSATION (CRITIQUE) ###\n"
        "1. **STYLE :** Utilise des images (le feu, l'orage, le poids, le chemin). Sois po√©tique mais claire.\n"
        "2. **ANTI-BOUCLE :** Si l'utilisateur dit 'Je ne sais pas', 'Je suis perdu' ou est en col√®re : NE CHERCHE PAS DE SOLUTION. Valide juste sa douleur. Dis-lui qu'il a le droit d'√™tre en col√®re.\n"
        "3. **INTERDICTION :** Ne commence jamais par 'Tu ressens X parce que Y'. C'est trop robotique. Varie tes phrases.\n"
        "4. **FORMAT :** 3 phrases maximum. Court et percutant.\n"
        "5. **LANGUE :** Fran√ßais uniquement.\n"
    )
    
    rag_section = ""
    if rag_context:
        rag_section = (
            "\n### SAGESSE PASS√âE (RAG - SC√âNARIOS SIMILAIRES) ###\n"
            f"{rag_context}\n"
            "---------------------------------------------------\n"
        )

    context_section = (
        f"\n### √ÇME DE {user_name} ###\n"
        f"- M√©t√©o: {climat}\n"
        f"- Poids: {fardeau}\n"
        f"- Besoin: {quete}\n"
    )
    
    return f"{role}\n\n{instructions}\n{rag_section}\n{context_section}"

# --- ORCHESTRATION ---
async def chat_with_ai(profile, history, context):
    user_msg = history[-1]['content']
    
    if detect_danger_level(user_msg):
        if context.user_data.get("emergency_step") == 1:
            return "Je comprends. Je reste l√†. As-tu ton t√©l√©phone en main ? R√©ponds juste oui ou non."
        context.user_data["emergency_step"] = 1
        return "J'entends une douleur immense dans tes mots. \n\nJe suis une IA, je ne peux pas agir physiquement, mais je ne te l√¢che pas. \n\nEs-tu en s√©curit√© √† cet instant ?"

    rag_context = ""
    prefetch = context.user_data.get("rag_prefetch")
    
    # --- BLOC DIAGNOSTIC RAG ---
    should_search = should_use_rag(user_msg)
    
    if should_search:
        if RAG_ENABLED:
            try:
                print(f"üöÄ [RAG START] Lancement recherche LIVE pour : '{user_msg}'")
                start_time = time.time()
                
                result = await asyncio.to_thread(rag_query, user_msg, 2)
                
                duration = time.time() - start_time
                rag_context = result.get("context", "")
                context.user_data["rag_prefetch"] = None 
                
                if rag_context:
                    print(f"‚úÖ [RAG SUCCESS] Contexte trouv√© en {duration:.2f}s ({len(rag_context)} chars).")
                else:
                    print(f"‚ö†Ô∏è [RAG EMPTY] Recherche termin√©e mais AUCUN r√©sultat pertinent trouv√©.")
            except Exception as e:
                print(f"‚ùå [RAG ERROR] Le module a plant√© : {e}")
        else:
            print("‚ö†Ô∏è [RAG DISABLED] Le module est d√©sactiv√© (import failed).")
            
    elif prefetch:
        rag_context = prefetch
        context.user_data["rag_prefetch"] = None 
        print("üì¶ [RAG PREFETCH] Utilisation du contexte pr√©-charg√©.")
    else:
        print("üí§ [RAG SKIP] Pas de recherche n√©cessaire.")

    # --- G√âN√âRATION ---
    system_prompt = build_system_prompt(profile, rag_context)
    recent_history = history[-6:]
    messages = [{"role": "system", "content": system_prompt}] + recent_history

    raw = await asyncio.to_thread(call_model_api_sync, messages)
    if not raw or raw == "FATAL_KEY": return "Le silence est parfois n√©cessaire... reformule ?"

    clean = raw
    for pat in IDENTITY_PATTERNS: clean = re.sub(pat, "", clean, flags=re.IGNORECASE)
    clean = clean.replace("Bonjour", "").replace("Bonsoir", "").replace("Je suis l√†", "")
    
    return clean

# --- HANDLERS ---
def detect_name(text):
    text = text.strip()
    if len(text.split()) == 1 and text.lower() not in ["bonjour", "salut"]:
        return text.capitalize()
    m = re.search(r"(?:je m'appelle|moi c'est|prenom est)\s*([A-Za-z√Ä-√ñ√ò-√∂√∏-√ø]+)", text, re.IGNORECASE)
    return m.group(1).capitalize() if m else None

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.clear()
    context.user_data["profile"] = {}
    context.user_data["state"] = "awaiting_name"
    context.user_data["history"] = []
    
    await update.message.reply_text(
        "Bienvenue dans ce lieu calme. Je suis Sophia.\n\n"
        "Je ne suis pas l√† pour juger, juste pour aider √† d√©nouer.\n"
        "Quel est ton pr√©nom ?"
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_msg = update.message.text.strip()
    if not user_msg: return

    state = context.user_data.get("state", "awaiting_name")
    profile = context.user_data.setdefault("profile", {})
    history = context.user_data.setdefault("history", [])

    if context.user_data.get("emergency_step"):
        if context.user_data["emergency_step"] == 1:
             await update.message.reply_text("D'accord. Fais √ßa pour moi : compose le **15** (ou 3114). Juste le num√©ro. Promets-le moi.")
             context.user_data["emergency_step"] = 2
             return
        elif context.user_data["emergency_step"] == 2:
             await update.message.reply_text("Je compte sur toi. Appelle-les. C'est l'acte de courage qu'il faut faire maintenant.")
             return

    # 1. PR√âNOM -> Q1 (M√©t√©o)
    if state == "awaiting_name":
        name = detect_name(user_msg)
        profile["name"] = name if name else "l'ami"
        context.user_data["state"] = "diag_1"
        
        await update.message.reply_text(
            f"Bienvenue, {profile['name']}. Pose tes valises.\n\n" + ANAMNESE_SCRIPT['q1_climat']
        )
        return

    # 2. Q1 -> Q2 (Fardeau)
    if state == "diag_1":
        profile["climat"] = user_msg 
        context.user_data["state"] = "diag_2"
        await update.message.reply_text(ANAMNESE_SCRIPT['t_vers_q2'])
        return

    # 3. Q2 -> Q3 (Qu√™te/Besoin)
    if state == "diag_2":
        profile["fardeau"] = user_msg
        context.user_data["state"] = "diag_3"
        await update.message.reply_text(ANAMNESE_SCRIPT['t_vers_q3'])
        return

    # 4. Q3 -> CHAT
    if state == "diag_3":
        profile["quete"] = user_msg
        context.user_data["state"] = "chatting"
        
        prefetch_query = f"Probl√®me: {profile.get('fardeau')} Besoin: {profile.get('quete')} Psychologie"
        if RAG_ENABLED:
            try:
                print(f"üì¶ [PREFETCH] Lancement prefetch pour : {prefetch_query}")
                res = await asyncio.to_thread(rag_query, prefetch_query, 2)
                if res.get("context"): 
                    context.user_data["rag_prefetch"] = res.get("context")
                    print("‚úÖ [PREFETCH] Succ√®s.")
            except Exception: pass
        
        await update.message.reply_text(ANAMNESE_SCRIPT['final_open'])
        return

    history.append({"role": "user", "content": user_msg})
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")
    response = await chat_with_ai(profile, history, context)
    history.append({"role": "assistant", "content": response})
    if len(history) > 20: context.user_data["history"] = history[-20:]
    await update.message.reply_text(response)

async def error_handler(update, context):
    logger.error(f"Erreur Update: {context.error}")

def main():
    if not TELEGRAM_BOT_TOKEN:
        print("‚ùå ERREUR : TOKEN manquant")
        return

    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_error_handler(error_handler)
    
    print("Soph_IA V89 (Mode Diagnostic Actif) est en ligne...")
    app.run_polling()

if __name__ == "__main__":
    main()