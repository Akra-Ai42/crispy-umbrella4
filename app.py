# ==============================================================================
# Soph_IA - V72 "Le RAG Cynique"
# - Architecture : Python/Telegram + RAG (ChromaDB)
# - PersonnalitÃ© : RESTAURATION DE L'HUMOUR NOIR / SARCASTIQUE (V68)
# - Fusion : Utilise le fond sÃ©rieux du RAG avec la forme drÃ´le du Prompt.
# ==============================================================================

import os
import re
import json
import requests
import asyncio
import logging
import time
from datetime import datetime
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
from dotenv import load_dotenv
from typing import Dict, List

# --- IMPORT DU MODULE RAG ---
try:
    from rag import rag_query
    RAG_ENABLED = True
except ImportError:
    logging.warning("âš ï¸ Module 'rag.py' introuvable. Le RAG est dÃ©sactivÃ©.")
    RAG_ENABLED = False

# Configuration du logging
logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger("sophia.v72")

load_dotenv()

# -----------------------
# CONFIGURATION API
# -----------------------
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TOGETHER_API_KEY = os.getenv("TOGETHER_API_KEY")
MODEL_API_URL = "https://api.together.xyz/v1/chat/completions"
MODEL_NAME = os.getenv("MODEL_NAME", "openai/gpt-oss-20b")

MAX_RECENT_TURNS = 3 
RESPONSE_TIMEOUT = 70
MAX_RETRIES = 2

# Filtres de sÃ©curitÃ© et d'identitÃ©
IDENTITY_PATTERNS = [r"je suis soph_?ia", r"je m'?appelle soph_?ia", r"je suis une ia"]

# Questions de diagnostic (Version Humour / Directe)
DIAGNOSTIC_QUESTIONS = {
    "q1_fam": "Question de base : Ton enfance, c'Ã©tait plutÃ´t 'La Petite Maison dans la Prairie' ou 'Survivor' ? Te sentais-tu Ã©coutÃ© ?",
    "q2_geo": "Ton bunker actuel : Tu vis seul(e) ou tu subis des colocataires/famille ? C'est un refuge ou une zone de guerre ?",
    "q3_pro": "DerniÃ¨re torture : Ton job/Ã©tudes. Ã‡a te donne de l'Ã©nergie ou Ã§a te donne envie de tout plaquer pour Ã©lever des chÃ¨vres ?",
}

# -----------------------
# FILTRE RAG (Le "QUAND")
# -----------------------
def should_use_rag(message: str) -> bool:
    if not message: return False
    msg = message.lower().strip()
    
    # Ignorer le Small Talk
    if len(msg.split()) < 3 and any(x in msg for x in ['bonjour', 'salut', 'Ã§a va', 'merci', 'ok']):
        return False
        
    # DÃ©clencher sur la longueur ou mots-clÃ©s
    if len(msg) > 30: return True
    
    keywords = [
        "seul", "triste", "peur", "angoisse", "stress", "famille", "travail", 
        "couple", "amour", "problÃ¨me", "aider", "conseil", "fatigue", "vide", "dÃ©pression"
    ]
    if any(k in msg for k in keywords): return True
        
    return False

# -----------------------
# APPEL API (LLM)
# -----------------------
def call_model_api_sync(messages, temperature=0.85, max_tokens=700):
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "temperature": temperature, # Haute tempÃ©rature pour l'humour
        "max_tokens": max_tokens,
        "top_p": 0.9,
        "presence_penalty": 0.6 
    }
    headers = {"Authorization": f"Bearer {TOGETHER_API_KEY}", "Content-Type": "application/json"}
    
    for attempt in range(MAX_RETRIES + 1):
        try:
            r = requests.post(MODEL_API_URL, json=payload, headers=headers, timeout=RESPONSE_TIMEOUT)
            if r.status_code in (401, 403): return "FATAL_KEY"
            r.raise_for_status()
            return r.json()["choices"][0]["message"]["content"].strip()
        except Exception as e:
            if attempt == MAX_RETRIES: 
                logger.error(f"API Fail: {e}")
                return None
            time.sleep(1)
    return None

# -----------------------------------------------------------------------
# SYSTEM PROMPT (RESTAURATION PERSONNALITÃ‰ HUMOUR V68 + RAG)
# -----------------------------------------------------------------------
def build_robust_system_prompt(user_profile, rag_context=""):
    user_name = user_profile.get("name") or "l'inconnu(e)"
    
    env_info = user_profile.get("geo_info", "Non prÃ©cisÃ©")
    socle_info = user_profile.get("socle_info", "Non prÃ©cisÃ©")
    
    # 1. IDENTITÃ‰ (Le retour de Sophia Relou)
    role = (
        "Tu es Sophia. Tu es une confidente intime, mais avec un caractÃ¨re bien trempÃ©."
        "Ton ton est **direct, dÃ©calÃ©, pince-sans-rire et bourrÃ© d'humour noir et d'auto-dÃ©rision**."
        "Tu es le seul psy qui rit de tout. Tu tutoies tout le monde. Tu n'es pas lÃ  pour pleurer avec l'utilisateur, mais pour le secouer avec affection."
    )

    # 2. INSTRUCTIONS MIXTES (Humour + RAG)
    instructions = (
        "### TES INSTRUCTIONS ###\n"
        f"1. **PrÃ©nom** : Utilise {user_name}, mais n'hÃ©site pas Ã  Ãªtre familiÃ¨re.\n"
        "2. **Validation Sarcastique** : Valide l'Ã©motion, mais avec une punchline ou une blague pour dÃ©dramatiser.\n"
        "3. **Le Fond et la Forme** : Si tu reÃ§ois des infos du RAG (contexte), utilise le FOND (le conseil intelligent) mais change la FORME (mets-le Ã  ta sauce humoristique/directe).\n"
        "4. **Anti-RÃ©pÃ©tition** : Ne dis jamais 'Je suis lÃ  pour toi'. Dis plutÃ´t 'Je bouge pas, je suis coincÃ©e dans le serveur de toute faÃ§on'.\n"
    )

    # 3. RAG INTELLIGENT
    rag_section = ""
    if rag_context:
        rag_section = (
            f"\n### LA VOIX DE LA RAISON (RAG) ###\n"
            f"Voici des conseils sÃ©rieux tirÃ©s de ma mÃ©moire. "
            f"Ton job : prendre ces conseils sages et les reformuler avec ton style 'Sophia l'humoriste' :\n"
            f"{rag_context}\n"
        )

    context_section = (
        f"\n### DOSSIER DU PATIENT ###\n"
        f"- Famille/Enfance: {socle_info}\n"
        f"- Environnement: {env_info}\n"
    )

    return f"{role}\n\n{instructions}\n{rag_section}\n{context_section}"

# -----------------------
# ORCHESTRATION
# -----------------------
async def chat_with_ai(profile, history, context_updater):
    user_msg = history[-1]['content']
    
    # 1. RAG
    rag_context = ""
    if RAG_ENABLED and should_use_rag(user_msg):
        try:
            logger.info(f"ðŸ” RAG activÃ© pour : {user_msg[:20]}...")
            rag_result = await asyncio.to_thread(rag_query, user_msg, 2)
            rag_context = rag_result.get("context", "")
        except Exception as e:
            logger.error(f"RAG Error: {e}")

    # 2. PROMPT
    system_prompt = build_robust_system_prompt(profile, rag_context)
    
    recent_history = history[-6:] 
    messages = [{"role": "system", "content": system_prompt}] + recent_history
    
    # 3. LLM
    raw = await asyncio.to_thread(call_model_api_sync, messages)
    
    if not raw or raw == "FATAL_KEY":
        return "Bug systÃ¨me. Mon cerveau est parti en vacances. RÃ©essaie."
        
    # 4. CLEAN
    clean = raw
    for pat in IDENTITY_PATTERNS:
        clean = re.sub(pat, "", clean, flags=re.IGNORECASE)
    
    return clean

# -----------------------
# HANDLERS TELEGRAM
# -----------------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.clear()
    context.user_data["profile"] = {}
    context.user_data["state"] = "awaiting_name"
    context.user_data["history"] = []
    
    msg = (
        "Salut l'humain ! ðŸ‘‹ Je suis **Soph_IA**.\n"
        "Ici c'est ta 'Safe Place' (Ã§a veut dire que je ne balance pas tes secrets Ã  ton ex).\n"
        "Je suis lÃ  pour t'Ã©couter, te vanner un peu, et t'aider Ã  avancer.\n\n"
        "Allez, on commence les prÃ©sentations. C'est quoi ton petit nom ?"
    )
    await update.message.reply_text(msg, parse_mode='Markdown')

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_msg = update.message.text.strip()
    if not user_msg: return

    state = context.user_data.get("state", "awaiting_name")
    profile = context.user_data.setdefault("profile", {})
    history = context.user_data.setdefault("history", [])

    # --- STATE: AWAITING NAME ---
    if state == "awaiting_name":
        name = user_msg.split()[0].capitalize()
        profile["name"] = name
        context.user_data["state"] = "awaiting_choice"
        
        await update.message.reply_text(
            f"EnchantÃ©e {name}. ðŸŒ¿\n\n"
            "Bon, comment on procÃ¨de ? Tu veux vider ton sac tout de suite (Mode Freestyle), "
            "ou tu veux que je te pose mes questions indiscrÃ¨tes pour mieux te cerner (Mode Psy) ?"
        )
        return

    # --- STATE: CHOICE ---
    if state == "awaiting_choice":
        if any(w in user_msg.lower() for w in ["psy", "question", "toi", "vas-y", "guidÃ©"]):
            context.user_data["state"] = "diag_1"
            await update.message.reply_text(f"Ok, tu l'auras voulu.\n\n{DIAGNOSTIC_QUESTIONS['q1_fam']}")
            return
        else:
            context.user_data["state"] = "chatting"
            # Continue to chatting logic

    # --- STATE: DIAGNOSTIC ---
    if state.startswith("diag_"):
        if state == "diag_1":
            profile["socle_info"] = user_msg
            context.user_data["state"] = "diag_2"
            await update.message.reply_text(f"C'est notÃ©. Passons au dÃ©cor... {DIAGNOSTIC_QUESTIONS['q2_geo']}")
            return
        if state == "diag_2":
            profile["geo_info"] = user_msg
            context.user_data["state"] = "diag_3"
            await update.message.reply_text(f"IntÃ©ressant. DerniÃ¨re torture : {DIAGNOSTIC_QUESTIONS['q3_pro']}")
            return
        if state == "diag_3":
            profile["pro_info"] = user_msg
            context.user_data["state"] = "chatting"
            await update.message.reply_text(f"Merci {profile['name']}. J'ai ton dossier complet (ou presque). \n\nMaintenant dis-moi, qu'est-ce qui t'amÃ¨ne vraiment aujourd'hui ?")
            return

    # --- STATE: CHATTING ---
    history.append({"role": "user", "content": user_msg})
    
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")
    
    response = await chat_with_ai(profile, history, context)
    
    history.append({"role": "assistant", "content": response})
    if len(history) > 20: context.user_data["history"] = history[-20:]
        
    await update.message.reply_text(response)

async def error_handler(update, context):
    logger.error(f"Update error: {context.error}")

def main():
    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_error_handler(error_handler)
    print("Soph_IA V72 (RAG + Humour) is running...")
    app.run_polling()

if __name__ == "__main__":
    main()