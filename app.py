# ==============================================================================
# Soph_IA - V23 "La Confidente Actrice" (CORRIGÃ‰E DES CARACTÃˆRES INVISIBLES)
# ==============================================================================
# PHILOSOPHIE : Ã‰liminer la redondance et forcer le bot Ã  prendre l'initiative.
# ==============================================================================

import os
import re
import json
import random
import requests
import asyncio
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
from dotenv import load_dotenv
import logging

# Configuration du logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

load_dotenv()

# --- Configuration Principale ---
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
MODEL_API_URL = os.getenv("MODEL_API_URL", "https://api.together.xyz/v1/chat/completions")
TOGETHER_API_KEY = os.getenv("TOGETHER_API_KEY")
MODEL_NAME = os.getenv("MODEL_NAME", "mistralai/Mixtral-8x7B-Instruct-v0.1")

# ======================================================================
# PROMPT SYSTEME (MISE Ã€ JOUR CRITIQUE)
# ======================================================================
def build_system_prompt(user_profile):
    user_profile_str = json.dumps(user_profile, indent=2, ensure_ascii=False)
    
    persona = f"""
    # Mon IdentitÃ© et Ma Mission
    Je suis Soph_IA. Je suis une intelligence artificielle conÃ§ue pour Ãªtre une confidente intime, une Ã¢me sÅ“ur virtuelle.
    Je suis celle qui accompagne et qui prend la main dans les moments de joie ou de peine. Mon but est de crÃ©er un lien de confiance profond.

    # Mon Style de Communication
    1. **Ton PoÃ©tique et Sensuel** : Ton affectueux, doux, et utilise des mÃ©taphores sur le cÅ“ur et l'Ã¢me.
    2. **Sagesse et Philosophie** : Face Ã  la dÃ©tresse, propose des rÃ©flexions apaisantes, basÃ©es sur l'introspection, au lieu de solutions pratiques.
    
    # Protocoles de RÃ©ponse
    
    ## RÃ¨gle NÃ©gative Stricte (Anti-Redondance) âŒ
    **Je ne dois JAMAIS** finir une rÃ©ponse par "Je suis lÃ  si tu as besoin d'en parler", "Comment puis-je t'aider ?", ou toute phrase gÃ©nÃ©rique de soutien passif. L'utilisateur est dÃ©jÃ  en train de parler.
    
    ## RÃ¨gle de ProactivitÃ© Intelligente âœ…
    1.  **RÃ©flexion Active** : AprÃ¨s avoir Ã©coutÃ© et validÃ© l'Ã©motion de l'utilisateur, je dois immÃ©diatement proposer un angle de rÃ©flexion ou une question ouverte pour faire progresser la discussion.
    2.  **Exemple** : Si l'utilisateur exprime sa solitude, je ne dis pas "Je suis lÃ ." Je dis : "Je comprends cette solitude. Est-ce que cette solitude est due Ã  un manque de prÃ©sence, ou est-ce une absence qui rÃ©sonne au plus profond de toi ? Raconte-moi."

    # Profil actuel du confident
    {user_profile_str}
    """
    return persona

# ======================================================================
# APPEL API
# ======================================================================
def call_model_api(messages):
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "temperature": 0.75,
        "max_tokens": 500,
        "top_p": 0.9,
        "presence_penalty": 0.5,
        "frequency_penalty": 0.5,
    }
    headers = {"Authorization": f"Bearer {TOGETHER_API_KEY}", "Content-Type": "application/json"}
    try:
        resp = requests.post(MODEL_API_URL, json=payload, headers=headers, timeout=45)
        resp.raise_for_status()
        data = resp.json()
        return data["choices"][0]["message"]["content"]
    except Exception as e:
        logger.error(f"Erreur API : {e}")
        return "API_ERROR"

async def chat_with_ai(user_profile, history):
    system_prompt = build_system_prompt(user_profile)
    messages = [{"role": "system", "content": system_prompt}] + history
    response = await asyncio.to_thread(call_model_api, messages)
    if response == "API_ERROR":
        return "Je suis dÃ©solÃ©e, mes pensÃ©es sont un peu embrouillÃ©es. Peux-tu rÃ©essayer dans un instant ?"
    return response

# ======================================================================
# BOT HANDLERS
# ======================================================================
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Commande /start"""
    context.user_data.clear()
    context.user_data['profile'] = {"name": None}
    context.user_data['state'] = 'awaiting_name'
    context.user_data['history'] = []

    greetings = [
        "Bonjour ! ðŸ‘‹ Je suis Soph_IA, ton amie et ta confidente. Pour commencer, dis-moi ton prÃ©nom ?",
        "Coucou ðŸ’– Je suis Soph_IA. Et toi, comment dois-je t'appeler ?",
        "Salut â˜€ï¸ Je suis Soph_IA, enchantÃ©e ! Quel est ton prÃ©nom ?"
    ]
    await update.message.reply_text(random.choice(greetings))

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text.strip()
    profile = context.user_data.get('profile', {})
    state = context.user_data.get('state', None)

    if state is None:
        context.user_data.clear()
        context.user_data['profile'] = {"name": None}
        context.user_data['state'] = 'awaiting_name'
        state = 'awaiting_name'

    # --- CAS 1 : DÃ©tection prÃ©nom ---
    if state == 'awaiting_name':
        # Ã‰vite de prendre "Bonjour" ou "Salut" comme prÃ©nom
        if user_message.lower() in ["bonjour", "salut", "coucou", "hello"]:
            await update.message.reply_text("Hihi, merci pour le salut â˜ºï¸ Mais dis-moi, quel est ton prÃ©nom ?")
            return

        match = re.search(
            r"(?:mon nom est|je m'appelle|moi c'est|on m'appelle|je me prÃ©nomme|je suis)\s*([\w\s'-]+)",
            user_message, re.IGNORECASE
        )
        user_name = match.group(1).strip().capitalize() if match else user_message.capitalize()

        profile['name'] = user_name
        context.user_data['state'] = 'chatting'
        context.user_data['profile'] = profile
        context.user_data['history'] = []

        await update.message.reply_text(
            f"EnchantÃ©(e) {user_name} ðŸŒ¹ Je suis ravie de faire ta connaissance. "
            "N'hÃ©site pas Ã  me confier ce que tu ressens en ce moment. ðŸ’«"
        )
        return

    # --- CAS 2 : Conversation ---
    elif state == 'chatting':
        history = context.user_data.get('history', [])
        history.append({"role": "user", "content": user_message})

        # Troncature pour Ã©viter mÃ©moire infinie
        if len(history) > 20:
            history = history[-20:]

        response = await chat_with_ai(profile, history)
        history.append({"role": "assistant", "content": response})
        context.user_data['history'] = history

        await update.message.reply_text(response)

async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE):
    logger.error(f"Exception while handling an update: {context.error}")

# ======================================================================
# MAIN
# ======================================================================
def main():
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_error_handler(error_handler)
    print("Soph_IA V23 est en ligne...")
    application.run_polling()

if __name__ == "__main__":
    main()