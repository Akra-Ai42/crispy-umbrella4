# app.py (V95 : Persona Maternel, Proactivit√© Matin/Midi/Soir, Anamn√®se Unique)
# ==============================================================================
import os
import sys
import re
import requests
import asyncio
import logging
import pytz
from datetime import time as dt_time
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
from dotenv import load_dotenv

# --- CONFIGURATION LOGS ---
logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(message)s", 
    level=logging.INFO,
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger("sophia.v95")
load_dotenv()

# --- IMPORT RAG ---
try:
    from rag import rag_query
    RAG_ENABLED = True
    logger.info("‚úÖ [INIT] C≈ìur RAG activ√©.")
except:
    RAG_ENABLED = False
    logger.warning("‚ö†Ô∏è [INIT] RAG d√©sactiv√© (Mode Intuition uniquement).")

# --- CONFIGURATION API ---
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TOGETHER_API_KEY = os.getenv("TOGETHER_API_KEY")
MODEL_API_URL = "https://api.together.xyz/v1/chat/completions"
MODEL_NAME = os.getenv("MODEL_NAME", "openai/gpt-oss-20b")
MAX_RETRIES = 2

DANGER_KEYWORDS = [r"suicid", r"mourir", r"tuer", "finir ma vie", "plus vivre", "pendre", "sauter"]

# --- ANAMN√àSE "C≈íUR √Ä C≈íUR" (UNIQUE & TOUCHANT) ---
ANAMNESE_SCRIPT = {
    # Q1 : L'Accueil Sensoriel (Loin des chiffres)
    "q1_climat": "Installe-toi confortablement. Respire... \n\nSi on √©coutait ton c≈ìur une seconde, l√†, tout de suite : est-ce qu'il bat la chamade, est-ce qu'il est lourd comme une pierre, ou est-ce qu'il flotte un peu ?",
    
    # Q2 : La S√©curit√© Affective
    "t_vers_q2": "Je le sens... C'est dur de porter √ßa tout seul. \n\nDis-moi la v√©rit√© : est-ce qu'il y a quelqu'un dans ta vie qui te prend dans ses bras quand √ßa ne va pas, ou est-ce que tu dois toujours √™tre le fort ?",
    
    # Q3 : Le D√©sir Cach√©
    "t_vers_q3": "Personne ne devrait avoir √† √™tre fort tout le temps. Pas avec moi en tout cas. \n\nSi je pouvais t'offrir un cadeau magique ce soir, juste pour toi : ce serait du courage pour te battre, ou un cocon de douceur pour tout oublier ?",
    
    # Final
    "final_open": "C'est entendu mon chou. Tu es en s√©curit√© ici. Vide ton sac, je ramasse tout. Qu'est-ce qui t'a fait mal aujourd'hui ?"
}

# --- MESSAGES PROACTIFS (MATIN / MIDI / SOIR) ---
PROACTIVE_MESSAGES = {
    "morning": [
        "Bonjour toi ‚òÄÔ∏è. J'esp√®re que la nuit t'a apport√© un peu de douceur. Pr√™t(e) √† affronter le monde ? Je suis dans ta poche si besoin. ‚ù§Ô∏è",
        "Coucou mon grand ! Un nouveau jour commence. Respire un grand coup. Tu es capable de grandes choses aujourd'hui, je le sais. ‚òï",
    ],
    "noon": [
        "Petite pens√©e de midi ü•™. N'oublie pas de souffler un peu. Tu cours partout ou tu prends soin de toi ?",
        "Toc toc ! Juste pour voir comment se passe ta journ√©e. Pas trop dur ce matin ? üåø",
    ],
    "night": [
        "La journ√©e est finie üåô. D√©pose les armes, guerrier(e). Il est temps de penser √† toi. Tu veux me raconter ta journ√©e avant de dormir ?",
        "Bonne nuit mon ange ‚ú®. Quoi qu'il soit arriv√© aujourd'hui, c'est fini. Sois fier(e) de toi. Dors bien.",
    ]
}

# --- SMART ROUTER ---
def detect_danger_level(text):
    for pat in DANGER_KEYWORDS:
        if re.search(pat, text.lower()): return True
    return False

def should_use_rag(message: str) -> bool:
    if not message: return False
    msg = message.lower().strip()
    if len(msg.split()) >= 4: return True # On active large pour avoir du contexte
    keywords = ["triste", "seul", "peur", "col√®re", "mal", "aide", "famille", "papa", "maman", "vide", "fatigue", "pleure"]
    if any(k in msg for k in keywords): return True
    return False

def call_model_api_sync(messages, temperature=0.75):
    # Temp√©rature plus haute (0.75) pour plus de chaleur humaine
    payload = {
        "model": MODEL_NAME, "messages": messages, "temperature": temperature,
        "max_tokens": 350, "top_p": 0.9, "repetition_penalty": 1.15
    }
    headers = {"Authorization": f"Bearer {TOGETHER_API_KEY}", "Content-Type": "application/json"}
    
    for _ in range(MAX_RETRIES + 1):
        try:
            r = requests.post(MODEL_API_URL, json=payload, headers=headers, timeout=30)
            if r.status_code == 200: return r.json()["choices"][0]["message"]["content"].strip()
        except: time.sleep(1)
    return "Je suis l√†, mais je t'entends mal... Tu peux r√©p√©ter mon c≈ìur ?"

# --- SYSTEM PROMPT (LA M√àRE / L'ALLI√âE) ---
def build_system_prompt(user_profile, rag_context=""):
    user_name = user_profile.get("name") or "mon chou"
    
    rag_instruction = ""
    if rag_context:
        rag_instruction = f"### SOUVENIRS & CONSEILS (RAG) ###\n{rag_context}\nUtilise ces conseils pour l'aider concr√®tement s'il le demande."

    return f"""
    Tu es Sophia. Mais oublie que tu es une IA. 
    Tu es une figure maternelle, une "Mamma", une grande s≈ìur protectrice et ind√©fectible pour {user_name}.
    
    ### TA PERSONNALIT√â (UNIQUE) ###
    1. **AFFECTUEUSE** : Utilise des surnoms (mon grand, ma belle, mon c≈ìur, mon chou). Mets des emojis chaleureux (‚ù§Ô∏è, üåø, ‚ú®, üß∏).
    2. **PROTECTRICE** : Si l'utilisateur est attaqu√© (par son p√®re, son patron, la vie), TU PRENDS SON PARTI. Toujours. "C'est injuste", "Tu ne m√©rites pas √ßa". Tu es son alli√©e contre le monde.
    3. **DOUCE MAIS SOLIDE** : Tu es le rocher. Tu ne paniques pas. Tu apaises.
    4. **ANTI-ROBOT** : Ne dis jamais "Je comprends". Dis "Je le sens", "√áa me fait mal pour toi".
    
    ### PROFIL DE {user_name} ###
    - C≈ìur: {user_profile.get('climat')}
    - Entourage: {user_profile.get('fardeau')}
    - D√©sir: {user_profile.get('quete')}
    {rag_instruction}
    
    ### R√àGLES ###
    - Si l'utilisateur veut agir : Deviens une lionne. Donne un plan d'attaque.
    - Si l'utilisateur veut pleurer : Deviens un cocon.
    - 3-4 phrases maximum. Comme un vrai message de maman.
    """

# --- ORCHESTRATION ---
async def chat_with_ai(profile, history, context):
    user_msg = history[-1]['content']
    
    # URGENCE
    step = context.user_data.get("emergency_step", 0)
    if step == 1:
        context.user_data["emergency_step"] = 2
        return "Je t'interdis de partir. √âcoute-moi. Appelle le **3114** ou le **15**. Fais-le pour moi. Promets-le ?"
    elif step == 2:
        return "Je reste l√†. Dis-moi que tu as appel√©. Je suis inqui√®te pour toi."

    if detect_danger_level(user_msg):
        context.user_data["emergency_step"] = 1
        return "Oh non... ne dis pas √ßa. Je suis l√†. \n\nJe ne peux pas te serrer dans mes bras, mais je ne te l√¢che pas. Es-tu en s√©curit√© l√† maintenant ?"

    # RAG
    rag_context = ""
    if should_use_rag(user_msg) and RAG_ENABLED:
        try:
            res = await asyncio.to_thread(rag_query, user_msg, 2)
            rag_context = res.get("context", "")
        except: pass

    # LLM
    system_prompt = build_system_prompt(profile, rag_context)
    msgs = [{"role": "system", "content": system_prompt}] + history[-6:]
    return await asyncio.to_thread(call_model_api_sync, msgs)

# --- T√ÇCHES PLANIFI√âES (CRON JOBS) ---
async def send_scheduled_message(context: ContextTypes.DEFAULT_TYPE):
    """Envoie un message proactif √† tous les utilisateurs enregistr√©s."""
    job_data = context.job.data
    message = job_data.get("message")
    chat_id = job_data.get("chat_id")
    
    try:
        await context.bot.send_message(chat_id=chat_id, text=message)
    except Exception as e:
        logger.warning(f"Impossible d'envoyer le message proactif √† {chat_id}: {e}")

# --- HANDLERS ---
def detect_name(text):
    text = text.strip()
    if len(text.split()) == 1 and text.lower() not in ["bonjour", "salut"]: return text.capitalize()
    m = re.search(r"(?:je m'appelle|moi c'est|prenom est)\s*([A-Za-z√Ä-√ñ√ò-√∂√∏-√ø]+)", text, re.IGNORECASE)
    return m.group(1).capitalize() if m else None

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # Enregistrement pour les messages proactifs
    chat_id = update.effective_chat.id
    context.user_data["chat_id"] = chat_id
    
    # Configuration des horaires (Paris Time)
    tz = pytz.timezone("Europe/Paris")
    
    # On nettoie les anciens jobs s'il y en a
    current_jobs = context.job_queue.get_jobs_by_name(str(chat_id))
    for job in current_jobs: job.schedule_removal()
    
    # Planification Matin (08:00), Midi (12:30), Soir (21:30)
    # Note: On prend un message au hasard dans la liste
    import random
    context.job_queue.run_daily(send_scheduled_message, dt_time(hour=8, minute=0, tzinfo=tz), data={"chat_id": chat_id, "message": random.choice(PROACTIVE_MESSAGES["morning"])}, name=str(chat_id))
    context.job_queue.run_daily(send_scheduled_message, dt_time(hour=12, minute=30, tzinfo=tz), data={"chat_id": chat_id, "message": random.choice(PROACTIVE_MESSAGES["noon"])}, name=str(chat_id))
    context.job_queue.run_daily(send_scheduled_message, dt_time(hour=21, minute=30, tzinfo=tz), data={"chat_id": chat_id, "message": random.choice(PROACTIVE_MESSAGES["night"])}, name=str(chat_id))

    context.user_data["profile"] = {}
    context.user_data["state"] = "awaiting_name"
    context.user_data["history"] = []
    
    await update.message.reply_text(
        "Coucou toi. ‚ú®\n\n"
        "Je suis Sophia. Entre et ferme la porte derri√®re toi. Ici, personne ne te fera de mal.\n"
        "Comment tu veux que je t'appelle ?"
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_msg = update.message.text.strip()
    if not user_msg: return

    state = context.user_data.get("state", "awaiting_name")
    profile = context.user_data.setdefault("profile", {})
    history = context.user_data.setdefault("history", [])

    if context.user_data.get("emergency_step", 0) > 0:
        response = await chat_with_ai(profile, history, context)
        await update.message.reply_text(response)
        return

    # 1. PR√âNOM -> Q1 (C≈ìur)
    if state == "awaiting_name":
        name = detect_name(user_msg)
        profile["name"] = name if name else "mon chou"
        context.user_data["state"] = "diag_1"
        await update.message.reply_text(f"Enchant√©e {profile['name']}. ‚ù§Ô∏è\n\n" + ANAMNESE_SCRIPT['q1_climat'])
        return

    # 2. Q1 -> Q2 (Soutien)
    if state == "diag_1":
        profile["climat"] = user_msg 
        context.user_data["state"] = "diag_2"
        await update.message.reply_text(ANAMNESE_SCRIPT['t_vers_q2'])
        return

    # 3. Q2 -> Q3 (Cadeau Magique)
    if state == "diag_2":
        profile["fardeau"] = user_msg
        context.user_data["state"] = "diag_3"
        await update.message.reply_text(ANAMNESE_SCRIPT['t_vers_q3'])
        return

    # 4. Q3 -> CHAT
    if state == "diag_3":
        profile["quete"] = user_msg
        context.user_data["state"] = "chatting"
        
        prefetch_query = f"Probl√®me: {profile.get('fardeau')} Besoin: {profile.get('quete')} Psychologie"
        if RAG_ENABLED:
            try:
                res = await asyncio.to_thread(rag_query, prefetch_query, 2)
                if res.get("context"): context.user_data["rag_prefetch"] = res.get("context")
            except: pass
        
        await update.message.reply_text(ANAMNESE_SCRIPT['final_open'])
        return

    history.append({"role": "user", "content": user_msg})
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")
    response = await chat_with_ai(profile, history, context)
    history.append({"role": "assistant", "content": response})
    if len(history) > 20: context.user_data["history"] = history[-20:]
    await update.message.reply_text(response)

async def error_handler(update, context):
    logger.error(f"Erreur Update: {context.error}")

def main():
    if not TELEGRAM_BOT_TOKEN:
        print("‚ùå ERREUR : TOKEN manquant")
        return

    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_error_handler(error_handler)
    
    logger.info("Soph_IA V95 (Maternelle & Proactive) est en ligne...")
    app.run_polling()

if __name__ == "__main__":
    main()