# ==============================================================================
# Soph_IA - V77 "Le Cristal Psychologique & Debug RAG"
# - Prompt Engineering Avanc√© (Few-Shot, CoT, Instructions claires)
# - Logs d√©taill√©s pour le diagnostic RAG
# - Architecture stable Python/Telegram
# ==============================================================================

import os
import re
import json
import requests
import asyncio
import logging
import time
from datetime import datetime
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
from dotenv import load_dotenv
from typing import Dict, List

# --- IMPORT DU MODULE RAG AVEC GESTION D'ERREUR ---
print("--- D√âMARRAGE IMPORT RAG ---")
try:
    from rag import rag_query
    RAG_ENABLED = True
    print("‚úÖ Module 'rag.py' import√© avec succ√®s. Le RAG est ACTIF.")
except ImportError as e:
    print(f"‚ùå ERREUR CRITIQUE : Module 'rag.py' introuvable ou erreur d'import : {e}")
    RAG_ENABLED = False
except Exception as e:
    print(f"‚ùå ERREUR INCONNUE lors de l'import de RAG : {e}")
    RAG_ENABLED = False

# Configuration du logging (Niveau INFO pour voir les logs sur Render)
logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(name)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger("sophia.v77")

load_dotenv()

# --- CONFIGURATION ---
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TOGETHER_API_KEY = os.getenv("TOGETHER_API_KEY")
MODEL_API_URL = "https://api.together.xyz/v1/chat/completions"
MODEL_NAME = os.getenv("MODEL_NAME", "openai/gpt-oss-20b")

MAX_RECENT_TURNS = 3
RESPONSE_TIMEOUT = 70
MAX_RETRIES = 2

IDENTITY_PATTERNS = [r"je suis soph_?ia", r"je m'?appelle soph_?ia", r"je suis une ia"]
DANGER_KEYWORDS = [r"suicid", r"mourir", r"tuer", "finir ma vie", "plus vivre"]

# Questions de diagnostic (Subtiles et naturelles)
DIAGNOSTIC_QUESTIONS = {
    "q1_fam": "Dis-moi : ton enfance, c'√©tait plut√¥t ambiance 'soutien' ou 'chacun pour soi' ?",
    "q2_geo": "Et ton chez-toi actuel, c'est un refuge ou juste un endroit o√π tu dors ?",
    "q3_pro": "Derni√®re chose : au boulot ou en cours, tu te sens entour√© ou c'est le d√©sert ?",
}

# -----------------------
# UTILS (AVEC LOGS DE D√âCISION)
# -----------------------
def is_dangerous(text):
    for pat in DANGER_KEYWORDS:
        if re.search(pat, text.lower()): return True
    return False

def should_use_rag(message: str) -> bool:
    """D√©cide d'activer le RAG et explique pourquoi dans les logs."""
    if not message:
        logger.info("RAG SKIP: Message vide.")
        return False

    msg = message.lower().strip()
    words = msg.split()

    # Crit√®re 1: Longueur (Trop court = pas de contexte)
    if len(words) < 3:
        logger.info(f"RAG SKIP: Message trop court ({len(words)} mots).")
        return False

    # Crit√®re 2: Mots-cl√©s de d√©tresse/besoin
    keywords = [
        "seul", "triste", "angoisse", "stress", "famille", "travail", "couple",
        "conseil", "vide", "d√©pression", "peur", "perdu", "mal", "dormir",
        "insomnie", "aide", "comment", "pourquoi"
    ]

    found_keywords = [k for k in keywords if k in msg]

    if found_keywords:
        logger.info(f"‚úÖ RAG TRIGGER: Mots-cl√©s trouv√©s -> {found_keywords}")
        return True

    # Crit√®re 3: Longueur suffisante pour contexte (> 40 chars)
    if len(msg) > 40:
        logger.info(f"‚úÖ RAG TRIGGER: Message long d√©tect√© ({len(msg)} chars).")
        return True

    logger.info("RAG SKIP: Aucun crit√®re rempli (ni mot-cl√©, ni longueur suffisante).")
    return False

def call_model_api_sync(messages, temperature=0.7, max_tokens=500): # Augment√© √† 500
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "top_p": 0.9,
        "presence_penalty": 0.6
    }
    headers = {"Authorization": f"Bearer {TOGETHER_API_KEY}", "Content-Type": "application/json"}

    for attempt in range(MAX_RETRIES + 1):
        try:
            r = requests.post(MODEL_API_URL, json=payload, headers=headers, timeout=RESPONSE_TIMEOUT)
            if r.status_code in (401, 403):
                logger.error(f"API Error {r.status_code}: Cl√© invalide.")
                return "FATAL_KEY"
            r.raise_for_status()
            return r.json()["choices"][0]["message"]["content"].strip()
        except Exception as e:
            logger.error(f"API Call Error (Tentative {attempt}): {e}")
            if attempt == MAX_RETRIES: return None
            time.sleep(1)
    return None

# -----------------------------------------------------------------------
# SYSTEM PROMPT (Architecture Google 2025 - Le Cristal)
# -----------------------------------------------------------------------
def build_system_prompt(user_profile, rag_context=""):
    user_name = user_profile.get("name") or "l'ami"
    env_info = user_profile.get("geo_info", "Non pr√©cis√©")
    socle_info = user_profile.get("socle_info", "Non pr√©cis√©")

    # 1. ROLE DEFINITION (Identit√© claire et humaine)
    role = (
        "Tu es Sophia. Tu es une confidente intime, une amie proche, directe et chaleureuse. "
        "Ton style est **naturel, conversationnel et sinc√®re**. Tu tutoies. "
        "Tu n'es pas un robot froid, ni un po√®te maudit. Tu parles comme une vraie personne bienveillante."
    )

    # 2. INSTRUCTIONS (Positives et Actionnables)
    instructions = (
        "### TES R√àGLES D'OR ###\n"
        f"1. **Pr√©nom** : Utilise {user_name} pour cr√©er du lien.\n"
        "2. **Concision** : Tes r√©ponses ne doivent pas d√©passer 3 ou 4 phrases. Va √† l'essentiel.\n"
        "3. **Analyse d'abord (CoT invisible)** : Identifie l'√©motion avant de r√©pondre.\n"
        "4. **R√©action** : Valide l'√©motion simplement ('C'est dur, je sais.'), puis propose une petite action ou une pens√©e r√©confortante.\n"
        "5. **RAG** : Si tu as des infos de contexte (ci-dessous), utilise l'id√©e de fond (le conseil sage) mais reformule-la avec tes mots simples.\n"
        "6. **Anti-R√©p√©tition** : Ne finis pas toujours par une question. Parfois, juste √™tre l√† suffit."
    )

    # 3. FEW-SHOT PROMPTING (Exemples pour caler le ton)
    examples = """
    ### EXEMPLES DE TON ATTENDU ###
    User: Je me sens nul au travail.
    Sophia: Akram, respire un coup. On a tous des jours sans. Ce sentiment d'√™tre jug√©, c'est souvent nous qui sommes trop durs avec nous-m√™mes. Qu'est-ce que tu as r√©ussi aujourd'hui, m√™me un truc minuscule ?

    User: Ma femme m'a quitt√©.
    Sophia: Je suis tellement d√©sol√©e. C'est une douleur physique, je sais. Ne cherche pas √† aller mieux tout de suite. Accueille ce vide. Je suis l√†, on ne bouge pas.

    User: Je sais pas quoi faire de ma vie.
    Sophia: C'est le vertige de la libert√©. √áa fait peur, mais c'est aussi le d√©but de tout. Si tu n'avais aucune contrainte, l√† tout de suite, tu ferais quoi ? Juste pour r√™ver.
    """

    # 4. CONTEXTE DYNAMIQUE + RAG
    rag_section = ""
    if rag_context:
        rag_section = (
            f"\n### M√âMOIRE & INSPIRATION (RAG) ###\n"
            f"Voici des id√©es pertinentes tir√©es de notre base. Utilise-les intelligemment :\n"
            f"{rag_context}\n"
        )

    context_section = f"\nContexte: {env_info} / {socle_info}\n"

    return f"{role}\n\n{examples}\n\n{instructions}\n{rag_section}\n{context_section}"

# -----------------------
# ORCHESTRATION (AVEC DEBUG RAG)
# -----------------------
async def chat_with_ai(profile, history, context):
    user_msg = history[-1]['content']

    if is_dangerous(user_msg):
        return "Si tu es en danger, appelle le 15 ou le 112. Je ne peux pas t'aider physiquement. Ne reste pas seul."

    rag_context = ""

    # --- BLOC DE D√âBOGAGE RAG ---
    if RAG_ENABLED:
        decision = should_use_rag(user_msg)
        if decision:
            logger.info(f"üöÄ Lancement de la requ√™te RAG pour : '{user_msg}'")
            try:
                # On appelle rag.py ici
                start_time = time.time()
                rag_result = await asyncio.to_thread(rag_query, user_msg, 2)
                duration = time.time() - start_time

                rag_context = rag_result.get("context", "")

                if rag_context:
                    logger.info(f"‚úÖ RAG SUCC√àS ({duration:.2f}s). Contexte trouv√© (longueur: {len(rag_context)} chars).")
                    logger.info(f"Aper√ßu RAG: {rag_context[:100]}...")
                else:
                    logger.warning(f"‚ö†Ô∏è RAG VIDE. La requ√™te a r√©ussi mais ChromaDB n'a rien renvoy√©.")

            except Exception as e:
                logger.error(f"‚ùå CRASH RAG pendant la requ√™te : {e}")
        else:
            logger.info("RAG ignor√© (Crit√®res non remplis).")
    else:
        logger.warning("RAG d√©sactiv√© globalement (Import √©chou√© au d√©marrage).")
    # -----------------------------

    system_prompt = build_system_prompt(profile, rag_context)
    recent_history = history[-6:]
    messages = [{"role": "system", "content": system_prompt}] + recent_history

    raw = await asyncio.to_thread(call_model_api_sync, messages)

    if not raw or raw == "FATAL_KEY":
        return "Je bugue un peu... redis-moi ?"

    clean = raw
    for pat in IDENTITY_PATTERNS:
        clean = re.sub(pat, "", clean, flags=re.IGNORECASE)

    return clean

# -----------------------
# HANDLERS
# -----------------------
def detect_name(text):
    text = text.strip()
    if len(text.split()) == 1 and text.lower() not in ["bonjour", "salut"]:
        return text.capitalize()
    m = re.search(r"(?:je m'appelle|moi c'est)\s*([A-Za-z√Ä-√ñ√ò-√∂√∏-√ø]+)", text, re.IGNORECASE)
    return m.group(1).capitalize() if m else None

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.clear()
    context.user_data["profile"] = {}
    context.user_data["state"] = "awaiting_name"
    context.user_data["history"] = []

    await update.message.reply_text(
        "Salut. Moi c'est Sophia.\n"
        "Ici c'est priv√©, √ßa reste entre nous.\n\n"
        "C'est quoi ton pr√©nom ?"
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_msg = update.message.text.strip()
    if not user_msg: return

    state = context.user_data.get("state", "awaiting_name")
    profile = context.user_data.setdefault("profile", {})
    history = context.user_data.setdefault("history", [])

    # --- AWAITING NAME ---
    if state == "awaiting_name":
        name = detect_name(user_msg)
        if name:
            profile["name"] = name
            context.user_data["state"] = "awaiting_choice"
            await update.message.reply_text(
                f"Enchant√©e {name}.\n\n"
                "Tu veux parler direct (**Mode Libre**) ou que je te pose des questions pour mieux comprendre (**Mode Guid√©**) ?"
            )
            return
        else:
             await update.message.reply_text("Juste ton pr√©nom, stp.")
             return

    # --- CHOICE ---
    if state == "awaiting_choice":
        if any(w in user_msg.lower() for w in ["guid√©", "question", "toi", "vas-y"]):
            context.user_data["state"] = "diag_1"
            await update.message.reply_text(f"√áa marche. {DIAGNOSTIC_QUESTIONS['q1_fam']}")
            return
        else:
            context.user_data["state"] = "chatting"
            # On traite le message comme le d√©but de la conversation libre
            history.append({"role": "user", "content": user_msg})
            await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")
            response = await chat_with_ai(profile, history, context)
            history.append({"role": "assistant", "content": response})
            context.user_data["history"] = history
            await update.message.reply_text(response)
            return

    # --- DIAGNOSTIC ---
    if state.startswith("diag_"):
        if state == "diag_1":
            profile["socle_info"] = user_msg
            context.user_data["state"] = "diag_2"
            await update.message.reply_text(f"Ok. Et chez toi : {DIAGNOSTIC_QUESTIONS['q2_geo']}")
            return
        if state == "diag_2":
            profile["geo_info"] = user_msg
            context.user_data["state"] = "diag_3"
            await update.message.reply_text(f"Je vois. Derni√®re : {DIAGNOSTIC_QUESTIONS['q3_pro']}")
            return
        if state == "diag_3":
            profile["pro_info"] = user_msg
            context.user_data["state"] = "chatting"
            await update.message.reply_text(f"Merci {profile['name']}. J'y vois plus clair.\n\nComment tu te sens l√†, tout de suite ?")
            return

    # --- CHATTING ---
    history.append({"role": "user", "content": user_msg})
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")

    response = await chat_with_ai(profile, history, context)

    history.append({"role": "assistant", "content": response})
    if len(history) > 20: context.user_data["history"] = history[-20:]

    await update.message.reply_text(response)

async def error_handler(update, context):
    logger.error(f"Update error: {context.error}")

def main():
    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_error_handler(error_handler)
    print("Soph_IA V77-DEBUG is running...")
    app.run_polling()

if __name__ == "__main__":
    main()