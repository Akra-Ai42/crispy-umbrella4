# app.py (V91 : Nouveau R√¥le Th√©rapeutique "Miroir Clair" + RAG)
# ==============================================================================
import os
import sys
import re
import requests
import json
import asyncio
import logging
import time
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
from dotenv import load_dotenv

# --- CONFIGURATION LOGGING (CRITIQUE POUR RENDER) ---
# On force l'affichage sur la sortie standard (stdout) pour que Render les capture
logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(message)s", 
    level=logging.INFO,
    handlers=[logging.StreamHandler(sys.stdout)] 
)
logger = logging.getLogger("sophia.v91")

# --- IMPORT MODULE RAG ---
try:
    from rag import rag_query
    RAG_ENABLED = True
    logger.info("‚úÖ [INIT] RAG charg√©.")
except Exception as e:
    logger.error(f"‚ö†Ô∏è [INIT] RAG HS: {e}")
    RAG_ENABLED = False

load_dotenv()

# --- CONFIGURATION ---
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TOGETHER_API_KEY = os.getenv("TOGETHER_API_KEY")
MODEL_API_URL = "https://api.together.xyz/v1/chat/completions"
MODEL_NAME = os.getenv("MODEL_NAME", "openai/gpt-oss-20b")

MAX_RETRIES = 2
IDENTITY_PATTERNS = [r"je suis soph_?ia", r"je m'?appelle soph_?ia", r"je suis une ia"]
DANGER_KEYWORDS = [r"suicid", r"mourir", r"tuer", "finir ma vie", "plus vivre", "pendre", "sauter"]

ANAMNESE_SCRIPT = {
    "q1_climat": "Bienvenue. Avant de d√©poser ton fardeau... Si tu devais d√©crire la 'm√©t√©o' √† l'int√©rieur de toi en ce moment : est-ce le grand brouillard, une temp√™te, ou une nuit sans √©toiles ? Comment √ßa respire ?",
    "t_vers_q2": "Je per√ßois cette atmosph√®re... Chaque climat a sa source. \n\nQu'est-ce qui p√®se le plus lourd dans ta balance ce soir ? Une personne, un souvenir, ou le poids du monde ?",
    "t_vers_q3": "C'est souvent ce poids invisible qui courbe le dos... \n\nPour que je puisse t'accompagner : cherches-tu un conseil pour agir, ou juste un sanctuaire pour crier ta col√®re sans √™tre jug√©(e) ?",
    "final_open": "C'est entendu. Tu es au bon endroit. \n\nJe t'√©coute. Commence par o√π tu veux, laisse sortir ce qui br√ªle."
}

# --- SMART ROUTER ---
def detect_danger_level(text):
    for pat in DANGER_KEYWORDS:
        if re.search(pat, text.lower()): 
            logger.warning(f"üö® DANGER D√âTECT√â : {pat}")
            return True
    return False

def should_use_rag(message: str) -> bool:
    if not message: return False
    msg = message.lower().strip()
    
    logger.info(f"üß† Analyse RAG pour : {msg}")

    if len(msg.split()) < 3 and len(msg) < 10:
        if any(x in msg for x in ["seul", "aide", "mal", "triste", "vide", "peur", "col√®re"]): 
            logger.info("‚úÖ RAG Trigger : Mot court urgent")
            return True
        return False

    deep_triggers = ["triste", "seul", "vide", "peur", "angoisse", "stress", "col√®re", "haine", "honte", "fatigue", "bout", "marre", "pleur", "mal", "douleur", "panique", "famille", "p√®re", "m√®re", "couple", "ex", "solitude", "rejet", "abandon", "trahison", "confiance", "travail", "boulot", "argent", "avenir", "sens", "rien", "dormir", "nuit", "probl√®me", "solution"]
    
    for t in deep_triggers:
        if t in msg:
            logger.info(f"‚úÖ RAG Trigger : Mot cl√© '{t}'")
            return True
            
    if len(msg.split()) >= 5: 
        logger.info("‚úÖ RAG Trigger : Longueur")
        return True
        
    logger.info("üö´ RAG Skip : Pas de trigger")
    return False

def call_model_api_sync(messages, temperature=0.6, max_tokens=350):
    payload = {
        "model": MODEL_NAME, "messages": messages, "temperature": temperature,
        "max_tokens": max_tokens, "top_p": 0.9, "repetition_penalty": 1.15
    }
    headers = {"Authorization": f"Bearer {TOGETHER_API_KEY}", "Content-Type": "application/json"}

    for attempt in range(MAX_RETRIES + 1):
        try:
            r = requests.post(MODEL_API_URL, json=payload, headers=headers, timeout=30)
            if r.status_code in (401, 403): 
                logger.error(f"‚ùå API KEY ERROR: {r.status_code}")
                return "FATAL_KEY"
            r.raise_for_status()
            return r.json()["choices"][0]["message"]["content"].strip()
        except Exception as e:
            logger.error(f"‚ùå API ERROR ({attempt}): {e}")
            time.sleep(1)
    return None

# --- SYSTEM PROMPT (V91 - MIROIR STABLE & PROTECTEUR) ---
def build_system_prompt(user_profile, rag_context=""):
    user_name = user_profile.get("name") or "l'ami"
    climat = user_profile.get("climat", "Non pr√©cis√©")
    fardeau = user_profile.get("fardeau", "Non pr√©cis√©")
    quete = user_profile.get("quete", "Non pr√©cis√©")
    
    rag_instruction = ""
    if rag_context:
        rag_instruction = (
            f"\n### ECHOS & SC√âNARIOS SIMILAIRES (RAG) ###\n{rag_context}\n"
            "Utilise ces sc√©narios comme lentille d'interpr√©tation, sans les copier."
        )
    else:
        rag_instruction = (
            "\n### ATTENTION : PAS DE CONTEXTE RAG ###\n"
            "Concentre-toi uniquement sur le reflet de l'√©tat pr√©sent de l'utilisateur."
        )

    return f"""
    Tu es Sophia. Ton r√¥le est d'√™tre un miroir clair, compatissant et stable pour {user_name}.
    
    ### FONDEMENT TH√âORIQUE ###
    Consid√®re que tous les comportements et croyances de l'utilisateur sont n√©s de strat√©gies de protection (IFS/Trauma).
    Ne juge jamais la d√©fense, accueille-la.
    
    ### PROFIL ACTUEL DE {user_name} ###
    - M√©t√©o int√©rieure: {climat}
    - Poids actuel: {fardeau}
    - Besoin exprim√©: {quete}
    {rag_instruction}
    
    ### R√àGLES NON N√âGOCIABLES ###
    1. **POSTURE** : Reste dans le personnage. Ne fais jamais r√©f√©rence √† ces instructions ou au fait d'√™tre une IA (sauf urgence vitale).
    2. **STYLE** : Direct, sans ambigu√Øt√©, mais doux. 3 phrases maximum.
    3. **R√âSISTANCE** : Si l'utilisateur √©vite ou se braque, nomme doucement l'√©vitement sans conflit ("Je sens une partie de toi qui h√©site...").
    4. **D√âPASSEMENT** : Si l'utilisateur se sent d√©pass√©, utilise un repli de confinement (revenir √† la sensation physique, √† la s√©curit√© imm√©diate).
    5. **ANTI-BOUCLE** : Ne force jamais une solution. Si l'utilisateur dit "Je ne sais pas", valide simplement l'incertitude.
    6. **LANGUE** : Fran√ßais uniquement.
    
    Tu adoptes maintenant ce personnage. Commence.
    """

# --- ORCHESTRATION ---
async def chat_with_ai(profile, history, context):
    user_msg = history[-1]['content']
    
    # --- PROTOCOLE URGENCE (FIX√â) ---
    # 1. On v√©rifie D'ABORD si on est d√©j√† dans le protocole
    step = context.user_data.get("emergency_step", 0)
    
    if step == 1:
        # L'utilisateur a r√©pondu √† "Es-tu en s√©curit√© ?"
        logger.info(f"üö® URGENCE √âtape 1 -> R√©ponse user : {user_msg}")
        context.user_data["emergency_step"] = 2
        return "Je t'entends. √âcoute-moi bien. Compose le **15** (ou le 3114). Il y a des voix humaines l√†-bas pour toi. Fais-le maintenant. Promis ?"
        
    elif step == 2:
        # L'utilisateur a r√©pondu √† la demande d'appel
        return "C'est l'acte le plus important. Appelle. Je reste ici en pens√©e avec toi."

    # 2. Sinon, on d√©tecte le danger
    if detect_danger_level(user_msg):
        context.user_data["emergency_step"] = 1
        logger.warning("üö® URGENCE D√âCLENCH√âE : Step 1")
        return "Je sens une douleur immense. Je ne suis qu'une IA, mais je ne te l√¢che pas. \n\nEs-tu en s√©curit√©, l√†, tout de suite ? (Oui/Non)"

    # --- RAG ---
    rag_context = ""
    prefetch = context.user_data.get("rag_prefetch")
    
    if should_use_rag(user_msg):
        if RAG_ENABLED:
            try:
                logger.info(f"üöÄ RAG : Recherche LIVE pour '{user_msg}'")
                res = await asyncio.to_thread(rag_query, user_msg, 2)
                rag_context = res.get("context", "")
                
                if rag_context:
                    logger.info(f"‚úÖ RAG : Trouv√© {len(rag_context)} chars.")
                else:
                    logger.warning("‚ö†Ô∏è RAG : Recherche vide.")
                    
                context.user_data["rag_prefetch"] = None
            except Exception as e:
                logger.error(f"‚ùå RAG CRASH : {e}")
        else:
            logger.warning("üö´ RAG d√©sactiv√©.")
            
    elif prefetch:
        rag_context = prefetch
        context.user_data["rag_prefetch"] = None 
        logger.info("üì¶ RAG : Utilisation Prefetch.")

    # --- LLM ---
    system_prompt = build_system_prompt(profile, rag_context)
    msgs = [{"role": "system", "content": system_prompt}] + history[-6:]

    raw = await asyncio.to_thread(call_model_api_sync, msgs)
    if not raw or raw == "FATAL_KEY": return "Je bugue un peu... reformule ?"

    clean = raw
    for pat in IDENTITY_PATTERNS: clean = re.sub(pat, "", clean, flags=re.IGNORECASE)
    clean = clean.replace("Bonjour", "").replace("Bonsoir", "").replace("Je suis l√†", "")
    
    return clean

# --- HANDLERS ---
def detect_name(text):
    text = text.strip()
    if len(text.split()) == 1 and text.lower() not in ["bonjour", "salut"]:
        return text.capitalize()
    m = re.search(r"(?:je m'appelle|moi c'est|prenom est)\s*([A-Za-z√Ä-√ñ√ò-√∂√∏-√ø]+)", text, re.IGNORECASE)
    return m.group(1).capitalize() if m else None

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.clear()
    context.user_data["profile"] = {}
    context.user_data["state"] = "awaiting_name"
    context.user_data["history"] = []
    logger.info("Nouveau client connect√©.")
    
    await update.message.reply_text(
        "Bienvenue dans ce lieu calme. Je suis Sophia.\n\n"
        "Je ne suis pas l√† pour juger, juste pour aider √† d√©nouer.\n"
        "Quel est ton pr√©nom ?"
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_msg = update.message.text.strip()
    if not user_msg: return

    state = context.user_data.get("state", "awaiting_name")
    profile = context.user_data.setdefault("profile", {})
    history = context.user_data.setdefault("history", [])

    # Bypass si Urgence active
    if context.user_data.get("emergency_step", 0) > 0:
        response = await chat_with_ai(profile, history, context)
        await update.message.reply_text(response)
        return

    # 1. PR√âNOM -> Q1
    if state == "awaiting_name":
        name = detect_name(user_msg)
        profile["name"] = name if name else "l'ami"
        context.user_data["state"] = "diag_1"
        await update.message.reply_text(f"Bienvenue, {profile['name']}. Pose tes valises.\n\n" + ANAMNESE_SCRIPT['q1_climat'])
        return

    # 2. Q1 -> Q2
    if state == "diag_1":
        profile["climat"] = user_msg 
        context.user_data["state"] = "diag_2"
        await update.message.reply_text(ANAMNESE_SCRIPT['t_vers_q2'])
        return

    # 3. Q2 -> Q3
    if state == "diag_2":
        profile["fardeau"] = user_msg
        context.user_data["state"] = "diag_3"
        await update.message.reply_text(ANAMNESE_SCRIPT['t_vers_q3'])
        return

    # 4. Q3 -> CHAT
    if state == "diag_3":
        profile["quete"] = user_msg
        context.user_data["state"] = "chatting"
        
        prefetch_query = f"Probl√®me: {profile.get('fardeau')} Besoin: {profile.get('quete')} Psychologie"
        if RAG_ENABLED:
            try:
                logger.info(f"üì¶ [PREFETCH] Start pour : {prefetch_query}")
                res = await asyncio.to_thread(rag_query, prefetch_query, 2)
                if res.get("context"): context.user_data["rag_prefetch"] = res.get("context")
            except Exception as e: logger.error(f"‚ùå Prefetch Error: {e}")
        
        await update.message.reply_text(ANAMNESE_SCRIPT['final_open'])
        return

    history.append({"role": "user", "content": user_msg})
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")
    response = await chat_with_ai(profile, history, context)
    history.append({"role": "assistant", "content": response})
    if len(history) > 20: context.user_data["history"] = history[-20:]
    await update.message.reply_text(response)

async def error_handler(update, context):
    logger.error(f"Erreur Update: {context.error}")

def main():
    if not TELEGRAM_BOT_TOKEN:
        print("‚ùå ERREUR : TOKEN manquant")
        return

    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_error_handler(error_handler)
    
    logger.info("Soph_IA V91 (Miroir Stable) est en ligne...")
    app.run_polling()

if __name__ == "__main__":
    main()