# app.py (V88 : Mix V86/V87 - Le Sage Pragmatique)
# ==============================================================================
import os
import re
import requests
import json
import asyncio
import logging
import time
from datetime import datetime
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
from dotenv import load_dotenv

# --- IMPORT MODULE RAG ---
try:
    from rag import rag_query
    RAG_ENABLED = True
    print("‚úÖ [INIT] Module RAG charg√©.")
except Exception as e:
    print(f"‚ö†Ô∏è [INIT] RAG non trouv√©: {e}")
    RAG_ENABLED = False

logging.basicConfig(format="%(asctime)s - %(levelname)s - %(message)s", level=logging.INFO)
logger = logging.getLogger("sophia.v88")
load_dotenv()

# --- CONFIGURATION ---
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TOGETHER_API_KEY = os.getenv("TOGETHER_API_KEY")
MODEL_API_URL = "https://api.together.xyz/v1/chat/completions"
MODEL_NAME = os.getenv("MODEL_NAME", "openai/gpt-oss-20b")

MAX_RETRIES = 2
IDENTITY_PATTERNS = [r"je suis soph_?ia", r"je m'?appelle soph_?ia", r"je suis une ia"]
DANGER_KEYWORDS = [r"suicid", r"mourir", r"tuer", "finir ma vie", "plus vivre", "pendre", "sauter"]

# --- ANAMN√àSE (RETOUR AUX M√âTAPHORES V86 - PLUS DOUX) ---
ANAMNESE_SCRIPT = {
    # Q1 : Climat (Plus po√©tique que "Quelle est ton √©motion ?")
    "q1_climat": "Bienvenue. Avant de d√©poser ton fardeau... Si tu devais d√©crire la 'm√©t√©o' √† l'int√©rieur de toi en ce moment : est-ce le grand brouillard, une temp√™te, ou une nuit sans √©toiles ? Comment √ßa respire ?",
    
    # Transition vers Q2 : Le Fardeau
    "t_vers_q2": "Je per√ßois cette atmosph√®re... Chaque climat a sa source. \n\nQu'est-ce qui p√®se le plus lourd dans ta balance ce soir ? Une personne, un souvenir, ou le poids du monde ?",
    
    # Transition vers Q3 : La Qu√™te (Besoin Pivot)
    "t_vers_q3": "C'est souvent ce poids invisible qui courbe le dos... \n\nPour que je puisse t'accompagner : cherches-tu un conseil pour agir, ou juste un sanctuaire pour crier ta col√®re sans √™tre jug√©(e) ?",
    
    # Final
    "final_open": "C'est entendu. Tu es au bon endroit. \n\nJe t'√©coute. Commence par o√π tu veux, laisse sortir ce qui br√ªle."
}

# --- SMART ROUTER ---
def detect_danger_level(text):
    for pat in DANGER_KEYWORDS:
        if re.search(pat, text.lower()): return True
    return False

def should_use_rag(message: str) -> bool:
    if not message: return False
    msg = message.lower().strip()
    if len(msg.split()) < 3 and len(msg) < 10:
        if any(x in msg for x in ["seul", "aide", "mal", "triste", "vide", "peur", "col√®re"]): return True
        return False
    deep_triggers = ["triste", "seul", "vide", "peur", "angoisse", "stress", "col√®re", "haine", "honte", "fatigue", "bout", "marre", "pleur", "mal", "douleur", "panique", "famille", "p√®re", "m√®re", "couple", "ex", "solitude", "rejet", "abandon", "trahison", "confiance", "travail", "boulot", "argent", "avenir", "sens", "rien", "dormir", "nuit", "probl√®me", "solution"]
    if any(t in msg for t in deep_triggers): return True
    if len(msg.split()) >= 5: return True
    return False

def call_model_api_sync(messages, temperature=0.7, max_tokens=350):
    # On remonte un peu la temp√©rature (0.7) pour plus de "chaleur" et moins de robotique
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "top_p": 0.9,
        "repetition_penalty": 1.2 # Augment√© pour √©viter les r√©p√©titions de phrases
    }
    headers = {"Authorization": f"Bearer {TOGETHER_API_KEY}", "Content-Type": "application/json"}

    for attempt in range(MAX_RETRIES + 1):
        try:
            r = requests.post(MODEL_API_URL, json=payload, headers=headers, timeout=30)
            if r.status_code in (401, 403): return "FATAL_KEY"
            r.raise_for_status()
            return r.json()["choices"][0]["message"]["content"].strip()
        except Exception:
            if attempt == MAX_RETRIES: return None
            time.sleep(1)
    return None

# --- SYSTEM PROMPT (VERSION HYBRIDE SAGE/PSY) ---
def build_system_prompt(user_profile, rag_context=""):
    user_name = user_profile.get("name") or "l'ami"
    climat = user_profile.get("climat", "Non pr√©cis√©")
    fardeau = user_profile.get("fardeau", "Non pr√©cis√©")
    quete = user_profile.get("quete", "Non pr√©cis√©")
    
    role = (
        "Tu es Sophia. Tu incarnes une 'Sagesse Ancienne' (M√©taphores, Calme) coupl√©e √† une √©coute active. "
        "Tu n'es pas un robot qui r√©p√®te, tu es un miroir bienveillant."
    )

    instructions = (
        "### R√àGLES DE CONVERSATION (CRITIQUE) ###\n"
        "1. **STYLE :** Utilise des images (le feu, l'orage, le poids, le chemin). Sois po√©tique mais claire.\n"
        "2. **ANTI-BOUCLE :** Si l'utilisateur dit 'Je ne sais pas', 'Je suis perdu' ou est en col√®re : NE CHERCHE PAS DE SOLUTION. Valide juste sa douleur. Dis-lui qu'il a le droit d'√™tre en col√®re.\n"
        "3. **INTERDICTION :** Ne commence jamais par 'Tu ressens X parce que Y'. C'est trop robotique. Varie tes phrases.\n"
        "4. **FORMAT :** 3 phrases maximum. Court et percutant.\n"
        "5. **LANGUE :** Fran√ßais uniquement.\n"
    )
    
    rag_section = ""
    if rag_context:
        rag_section = (
            "\n### SAGESSE PASS√âE (RAG) ###\n"
            f"{rag_context}\n"
            "---------------------------------------------------\n"
        )

    context_section = (
        f"\n### √ÇME DE {user_name} ###\n"
        f"- M√©t√©o: {climat}\n"
        f"- Poids: {fardeau}\n"
        f"- Besoin: {quete}\n"
    )
    
    return f"{role}\n\n{instructions}\n{rag_section}\n{context_section}"

# --- ORCHESTRATION ---
async def chat_with_ai(profile, history, context):
    user_msg = history[-1]['content']
    
    if detect_danger_level(user_msg):
        if context.user_data.get("emergency_step") == 1:
            return "Je comprends. Je reste l√†. As-tu ton t√©l√©phone en main ? R√©ponds juste oui ou non."
        context.user_data["emergency_step"] = 1
        return "J'entends une douleur immense dans tes mots. \n\nJe suis une IA, je ne peux pas agir physiquement, mais je ne te l√¢che pas. \n\nEs-tu en s√©curit√© √† cet instant ?"

    rag_context = ""
    prefetch = context.user_data.get("rag_prefetch")
    
    if should_use_rag(user_msg):
        try:
            print(f"üîç [RAG] Recherche LIVE : {user_msg[:30]}...")
            result = await asyncio.to_thread(rag_query, user_msg, 2)
            rag_context = result.get("context", "")
            context.user_data["rag_prefetch"] = None 
        except Exception: pass
    elif prefetch:
        rag_context = prefetch
        context.user_data["rag_prefetch"] = None 

    system_prompt = build_system_prompt(profile, rag_context)
    recent_history = history[-6:]
    messages = [{"role": "system", "content": system_prompt}] + recent_history

    raw = await asyncio.to_thread(call_model_api_sync, messages)
    if not raw or raw == "FATAL_KEY": return "Le silence est parfois n√©cessaire... reformule ?"

    clean = raw
    for pat in IDENTITY_PATTERNS: clean = re.sub(pat, "", clean, flags=re.IGNORECASE)
    clean = clean.replace("Bonjour", "").replace("Bonsoir", "").replace("Je suis l√†", "")
    
    return clean

# --- HANDLERS ---
def detect_name(text):
    text = text.strip()
    if len(text.split()) == 1 and text.lower() not in ["bonjour", "salut"]:
        return text.capitalize()
    m = re.search(r"(?:je m'appelle|moi c'est|prenom est)\s*([A-Za-z√Ä-√ñ√ò-√∂√∏-√ø]+)", text, re.IGNORECASE)
    return m.group(1).capitalize() if m else None

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.clear()
    context.user_data["profile"] = {}
    context.user_data["state"] = "awaiting_name"
    context.user_data["history"] = []
    
    await update.message.reply_text(
        "Bienvenue dans ce lieu calme. Je suis Sophia.\n\n"
        "Je ne suis pas l√† pour juger, juste pour aider √† d√©nouer.\n"
        "Quel est ton pr√©nom ?"
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_msg = update.message.text.strip()
    if not user_msg: return

    state = context.user_data.get("state", "awaiting_name")
    profile = context.user_data.setdefault("profile", {})
    history = context.user_data.setdefault("history", [])

    if context.user_data.get("emergency_step"):
        if context.user_data["emergency_step"] == 1:
             await update.message.reply_text("D'accord. Fais √ßa pour moi : compose le **15** (ou 3114). Juste le num√©ro. Promets-le moi.")
             context.user_data["emergency_step"] = 2
             return
        elif context.user_data["emergency_step"] == 2:
             await update.message.reply_text("Je compte sur toi. Appelle-les. C'est l'acte de courage qu'il faut faire maintenant.")
             return

    # 1. PR√âNOM -> Q1 (M√©t√©o)
    if state == "awaiting_name":
        name = detect_name(user_msg)
        profile["name"] = name if name else "l'ami"
        context.user_data["state"] = "diag_1"
        
        await update.message.reply_text(
            f"Bienvenue, {profile['name']}. Pose tes valises.\n\n" + ANAMNESE_SCRIPT['q1_climat']
        )
        return

    # 2. Q1 -> Q2 (Fardeau)
    if state == "diag_1":
        profile["climat"] = user_msg 
        context.user_data["state"] = "diag_2"
        await update.message.reply_text(ANAMNESE_SCRIPT['t_vers_q2'])
        return

    # 3. Q2 -> Q3 (Qu√™te/Besoin)
    if state == "diag_2":
        profile["fardeau"] = user_msg
        context.user_data["state"] = "diag_3"
        await update.message.reply_text(ANAMNESE_SCRIPT['t_vers_q3'])
        return

    # 4. Q3 -> CHAT
    if state == "diag_3":
        profile["quete"] = user_msg
        context.user_data["state"] = "chatting"
        
        prefetch_query = f"Probl√®me: {profile.get('fardeau')} Besoin: {profile.get('quete')} Psychologie"
        if RAG_ENABLED:
            try:
                res = await asyncio.to_thread(rag_query, prefetch_query, 2)
                if res.get("context"): context.user_data["rag_prefetch"] = res.get("context")
            except Exception: pass
        
        await update.message.reply_text(ANAMNESE_SCRIPT['final_open'])
        return

    history.append({"role": "user", "content": user_msg})
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")
    response = await chat_with_ai(profile, history, context)
    history.append({"role": "assistant", "content": response})
    if len(history) > 20: context.user_data["history"] = history[-20:]
    await update.message.reply_text(response)

async def error_handler(update, context):
    logger.error(f"Erreur Update: {context.error}")

def main():
    if not TELEGRAM_BOT_TOKEN:
        print("‚ùå ERREUR : TOKEN manquant")
        return

    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_error_handler(error_handler)
    
    print("Soph_IA V88 (Mix Sage/Pragmatique) est en ligne...")
    app.run_polling()

if __name__ == "__main__":
    main()